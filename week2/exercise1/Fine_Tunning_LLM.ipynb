{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evinracher/3008410-intelligent-systems/blob/main/week2/exercise1/Fine_Tunning_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61b78358-4060-48f8-9060-200e146ae636",
      "metadata": {
        "id": "61b78358-4060-48f8-9060-200e146ae636",
        "outputId": "f44024a8-f0b4-4e1d-d36a-3fa43c8e4a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from datasets) (2.1.3)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from datasets) (2.32.3)\n",
            "Collecting tqdm>=4.66.3 (from datasets)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.32.6-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from datasets) (25.0)\n",
            "Collecting pyyaml>=5.1 (from datasets)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading aiohttp-3.12.12-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Collecting colorama (from tqdm>=4.66.3->datasets)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading multidict-6.4.4-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\john\\miniconda312\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Downloading huggingface_hub-0.32.6-py3-none-any.whl (512 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl (25.8 MB)\n",
            "   ---------------------------------------- 0.0/25.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/25.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/25.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.3/25.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.3/25.8 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.5/25.8 MB 578.7 kB/s eta 0:00:44\n",
            "    --------------------------------------- 0.5/25.8 MB 578.7 kB/s eta 0:00:44\n",
            "   - -------------------------------------- 0.8/25.8 MB 578.7 kB/s eta 0:00:44\n",
            "   - -------------------------------------- 0.8/25.8 MB 578.7 kB/s eta 0:00:44\n",
            "   - -------------------------------------- 0.8/25.8 MB 578.7 kB/s eta 0:00:44\n",
            "   - -------------------------------------- 1.0/25.8 MB 488.8 kB/s eta 0:00:51\n",
            "   - -------------------------------------- 1.0/25.8 MB 488.8 kB/s eta 0:00:51\n",
            "   - -------------------------------------- 1.0/25.8 MB 488.8 kB/s eta 0:00:51\n",
            "   -- ------------------------------------- 1.3/25.8 MB 476.0 kB/s eta 0:00:52\n",
            "   -- ------------------------------------- 1.3/25.8 MB 476.0 kB/s eta 0:00:52\n",
            "   -- ------------------------------------- 1.3/25.8 MB 476.0 kB/s eta 0:00:52\n",
            "   -- ------------------------------------- 1.6/25.8 MB 479.4 kB/s eta 0:00:51\n",
            "   -- ------------------------------------- 1.6/25.8 MB 479.4 kB/s eta 0:00:51\n",
            "   -- ------------------------------------- 1.8/25.8 MB 479.4 kB/s eta 0:00:50\n",
            "   -- ------------------------------------- 1.8/25.8 MB 479.4 kB/s eta 0:00:50\n",
            "   -- ------------------------------------- 1.8/25.8 MB 479.4 kB/s eta 0:00:50\n",
            "   --- ------------------------------------ 2.1/25.8 MB 477.5 kB/s eta 0:00:50\n",
            "   --- ------------------------------------ 2.1/25.8 MB 477.5 kB/s eta 0:00:50\n",
            "   --- ------------------------------------ 2.4/25.8 MB 482.9 kB/s eta 0:00:49\n",
            "   --- ------------------------------------ 2.4/25.8 MB 482.9 kB/s eta 0:00:49\n",
            "   --- ------------------------------------ 2.4/25.8 MB 482.9 kB/s eta 0:00:49\n",
            "   ---- ----------------------------------- 2.6/25.8 MB 480.9 kB/s eta 0:00:49\n",
            "   ---- ----------------------------------- 2.6/25.8 MB 480.9 kB/s eta 0:00:49\n",
            "   ---- ----------------------------------- 2.6/25.8 MB 480.9 kB/s eta 0:00:49\n",
            "   ---- ----------------------------------- 2.9/25.8 MB 479.4 kB/s eta 0:00:48\n",
            "   ---- ----------------------------------- 2.9/25.8 MB 479.4 kB/s eta 0:00:48\n",
            "   ---- ----------------------------------- 3.1/25.8 MB 484.4 kB/s eta 0:00:47\n",
            "   ---- ----------------------------------- 3.1/25.8 MB 484.4 kB/s eta 0:00:47\n",
            "   ---- ----------------------------------- 3.1/25.8 MB 484.4 kB/s eta 0:00:47\n",
            "   ----- ---------------------------------- 3.4/25.8 MB 484.0 kB/s eta 0:00:47\n",
            "   ----- ---------------------------------- 3.4/25.8 MB 484.0 kB/s eta 0:00:47\n",
            "   ----- ---------------------------------- 3.4/25.8 MB 484.0 kB/s eta 0:00:47\n",
            "   ----- ---------------------------------- 3.7/25.8 MB 471.1 kB/s eta 0:00:47\n",
            "   ----- ---------------------------------- 3.7/25.8 MB 471.1 kB/s eta 0:00:47\n",
            "   ----- ---------------------------------- 3.7/25.8 MB 471.1 kB/s eta 0:00:47\n",
            "   ------ --------------------------------- 3.9/25.8 MB 469.8 kB/s eta 0:00:47\n",
            "   ------ --------------------------------- 3.9/25.8 MB 469.8 kB/s eta 0:00:47\n",
            "   ------ --------------------------------- 4.2/25.8 MB 474.0 kB/s eta 0:00:46\n",
            "   ------ --------------------------------- 4.2/25.8 MB 474.0 kB/s eta 0:00:46\n",
            "   ------ --------------------------------- 4.2/25.8 MB 474.0 kB/s eta 0:00:46\n",
            "   ------ --------------------------------- 4.5/25.8 MB 475.1 kB/s eta 0:00:45\n",
            "   ------ --------------------------------- 4.5/25.8 MB 475.1 kB/s eta 0:00:45\n",
            "   ------ --------------------------------- 4.5/25.8 MB 475.1 kB/s eta 0:00:45\n",
            "   ------- -------------------------------- 4.7/25.8 MB 476.2 kB/s eta 0:00:45\n",
            "   ------- -------------------------------- 4.7/25.8 MB 476.2 kB/s eta 0:00:45\n",
            "   ------- -------------------------------- 5.0/25.8 MB 480.1 kB/s eta 0:00:44\n",
            "   ------- -------------------------------- 5.0/25.8 MB 480.1 kB/s eta 0:00:44\n",
            "   ------- -------------------------------- 5.0/25.8 MB 480.1 kB/s eta 0:00:44\n",
            "   -------- ------------------------------- 5.2/25.8 MB 475.1 kB/s eta 0:00:44\n",
            "   -------- ------------------------------- 5.2/25.8 MB 475.1 kB/s eta 0:00:44\n",
            "   -------- ------------------------------- 5.5/25.8 MB 477.3 kB/s eta 0:00:43\n",
            "   -------- ------------------------------- 5.5/25.8 MB 477.3 kB/s eta 0:00:43\n",
            "   -------- ------------------------------- 5.5/25.8 MB 477.3 kB/s eta 0:00:43\n",
            "   -------- ------------------------------- 5.8/25.8 MB 481.3 kB/s eta 0:00:42\n",
            "   -------- ------------------------------- 5.8/25.8 MB 481.3 kB/s eta 0:00:42\n",
            "   --------- ------------------------------ 6.0/25.8 MB 481.9 kB/s eta 0:00:41\n",
            "   --------- ------------------------------ 6.0/25.8 MB 481.9 kB/s eta 0:00:41\n",
            "   --------- ------------------------------ 6.3/25.8 MB 484.2 kB/s eta 0:00:41\n",
            "   --------- ------------------------------ 6.3/25.8 MB 484.2 kB/s eta 0:00:41\n",
            "   --------- ------------------------------ 6.3/25.8 MB 484.2 kB/s eta 0:00:41\n",
            "   ---------- ----------------------------- 6.6/25.8 MB 485.7 kB/s eta 0:00:40\n",
            "   ---------- ----------------------------- 6.6/25.8 MB 485.7 kB/s eta 0:00:40\n",
            "   ---------- ----------------------------- 6.8/25.8 MB 487.7 kB/s eta 0:00:39\n",
            "   ---------- ----------------------------- 6.8/25.8 MB 487.7 kB/s eta 0:00:39\n",
            "   ---------- ----------------------------- 7.1/25.8 MB 492.4 kB/s eta 0:00:38\n",
            "   ---------- ----------------------------- 7.1/25.8 MB 492.4 kB/s eta 0:00:38\n",
            "   ---------- ----------------------------- 7.1/25.8 MB 492.4 kB/s eta 0:00:38\n",
            "   ----------- ---------------------------- 7.3/25.8 MB 492.9 kB/s eta 0:00:38\n",
            "   ----------- ---------------------------- 7.6/25.8 MB 498.2 kB/s eta 0:00:37\n",
            "   ----------- ---------------------------- 7.6/25.8 MB 498.2 kB/s eta 0:00:37\n",
            "   ------------ --------------------------- 7.9/25.8 MB 502.6 kB/s eta 0:00:36\n",
            "   ------------ --------------------------- 7.9/25.8 MB 502.6 kB/s eta 0:00:36\n",
            "   ------------ --------------------------- 8.1/25.8 MB 507.9 kB/s eta 0:00:35\n",
            "   ------------ --------------------------- 8.1/25.8 MB 507.9 kB/s eta 0:00:35\n",
            "   ------------- -------------------------- 8.4/25.8 MB 509.9 kB/s eta 0:00:35\n",
            "   ------------- -------------------------- 8.4/25.8 MB 509.9 kB/s eta 0:00:35\n",
            "   ------------- -------------------------- 8.7/25.8 MB 515.7 kB/s eta 0:00:34\n",
            "   ------------- -------------------------- 8.7/25.8 MB 515.7 kB/s eta 0:00:34\n",
            "   ------------- -------------------------- 8.9/25.8 MB 518.9 kB/s eta 0:00:33\n",
            "   ------------- -------------------------- 8.9/25.8 MB 518.9 kB/s eta 0:00:33\n",
            "   -------------- ------------------------- 9.2/25.8 MB 520.9 kB/s eta 0:00:32\n",
            "   -------------- ------------------------- 9.2/25.8 MB 520.9 kB/s eta 0:00:32\n",
            "   -------------- ------------------------- 9.4/25.8 MB 524.8 kB/s eta 0:00:32\n",
            "   -------------- ------------------------- 9.4/25.8 MB 524.8 kB/s eta 0:00:32\n",
            "   --------------- ------------------------ 9.7/25.8 MB 528.9 kB/s eta 0:00:31\n",
            "   --------------- ------------------------ 10.0/25.8 MB 534.2 kB/s eta 0:00:30\n",
            "   --------------- ------------------------ 10.0/25.8 MB 534.2 kB/s eta 0:00:30\n",
            "   --------------- ------------------------ 10.2/25.8 MB 538.0 kB/s eta 0:00:29\n",
            "   ---------------- ----------------------- 10.5/25.8 MB 543.5 kB/s eta 0:00:29\n",
            "   ---------------- ----------------------- 10.5/25.8 MB 543.5 kB/s eta 0:00:29\n",
            "   ---------------- ----------------------- 10.7/25.8 MB 546.5 kB/s eta 0:00:28\n",
            "   ----------------- ---------------------- 11.0/25.8 MB 552.1 kB/s eta 0:00:27\n",
            "   ----------------- ---------------------- 11.0/25.8 MB 552.1 kB/s eta 0:00:27\n",
            "   ----------------- ---------------------- 11.0/25.8 MB 552.1 kB/s eta 0:00:27\n",
            "   ----------------- ---------------------- 11.3/25.8 MB 553.1 kB/s eta 0:00:27\n",
            "   ----------------- ---------------------- 11.5/25.8 MB 557.9 kB/s eta 0:00:26\n",
            "   ----------------- ---------------------- 11.5/25.8 MB 557.9 kB/s eta 0:00:26\n",
            "   ------------------ --------------------- 11.8/25.8 MB 558.8 kB/s eta 0:00:26\n",
            "   ------------------ --------------------- 11.8/25.8 MB 558.8 kB/s eta 0:00:26\n",
            "   ------------------ --------------------- 12.1/25.8 MB 558.0 kB/s eta 0:00:25\n",
            "   ------------------ --------------------- 12.1/25.8 MB 558.0 kB/s eta 0:00:25\n",
            "   ------------------ --------------------- 12.1/25.8 MB 558.0 kB/s eta 0:00:25\n",
            "   ------------------- -------------------- 12.3/25.8 MB 558.8 kB/s eta 0:00:25\n",
            "   ------------------- -------------------- 12.3/25.8 MB 558.8 kB/s eta 0:00:25\n",
            "   ------------------- -------------------- 12.6/25.8 MB 557.7 kB/s eta 0:00:24\n",
            "   ------------------- -------------------- 12.6/25.8 MB 557.7 kB/s eta 0:00:24\n",
            "   ------------------- -------------------- 12.8/25.8 MB 560.4 kB/s eta 0:00:24\n",
            "   -------------------- ------------------- 13.1/25.8 MB 562.7 kB/s eta 0:00:23\n",
            "   -------------------- ------------------- 13.1/25.8 MB 562.7 kB/s eta 0:00:23\n",
            "   -------------------- ------------------- 13.4/25.8 MB 564.9 kB/s eta 0:00:22\n",
            "   -------------------- ------------------- 13.4/25.8 MB 564.9 kB/s eta 0:00:22\n",
            "   --------------------- ------------------ 13.6/25.8 MB 565.5 kB/s eta 0:00:22\n",
            "   --------------------- ------------------ 13.6/25.8 MB 565.5 kB/s eta 0:00:22\n",
            "   --------------------- ------------------ 13.9/25.8 MB 568.0 kB/s eta 0:00:21\n",
            "   --------------------- ------------------ 13.9/25.8 MB 568.0 kB/s eta 0:00:21\n",
            "   --------------------- ------------------ 14.2/25.8 MB 571.5 kB/s eta 0:00:21\n",
            "   ---------------------- ----------------- 14.4/25.8 MB 573.4 kB/s eta 0:00:20\n",
            "   ---------------------- ----------------- 14.4/25.8 MB 573.4 kB/s eta 0:00:20\n",
            "   ---------------------- ----------------- 14.7/25.8 MB 575.3 kB/s eta 0:00:20\n",
            "   ---------------------- ----------------- 14.7/25.8 MB 575.3 kB/s eta 0:00:20\n",
            "   ----------------------- ---------------- 14.9/25.8 MB 577.1 kB/s eta 0:00:19\n",
            "   ----------------------- ---------------- 14.9/25.8 MB 577.1 kB/s eta 0:00:19\n",
            "   ----------------------- ---------------- 15.2/25.8 MB 579.6 kB/s eta 0:00:19\n",
            "   ----------------------- ---------------- 15.2/25.8 MB 579.6 kB/s eta 0:00:19\n",
            "   ----------------------- ---------------- 15.2/25.8 MB 579.6 kB/s eta 0:00:19\n",
            "   ----------------------- ---------------- 15.5/25.8 MB 574.4 kB/s eta 0:00:18\n",
            "   ------------------------ --------------- 15.7/25.8 MB 578.9 kB/s eta 0:00:18\n",
            "   ------------------------ --------------- 15.7/25.8 MB 578.9 kB/s eta 0:00:18\n",
            "   ------------------------ --------------- 16.0/25.8 MB 581.6 kB/s eta 0:00:17\n",
            "   ------------------------ --------------- 16.0/25.8 MB 581.6 kB/s eta 0:00:17\n",
            "   ------------------------ --------------- 16.0/25.8 MB 581.6 kB/s eta 0:00:17\n",
            "   ------------------------- -------------- 16.3/25.8 MB 578.2 kB/s eta 0:00:17\n",
            "   ------------------------- -------------- 16.5/25.8 MB 581.8 kB/s eta 0:00:16\n",
            "   ------------------------- -------------- 16.5/25.8 MB 581.8 kB/s eta 0:00:16\n",
            "   -------------------------- ------------- 16.8/25.8 MB 581.7 kB/s eta 0:00:16\n",
            "   -------------------------- ------------- 16.8/25.8 MB 581.7 kB/s eta 0:00:16\n",
            "   -------------------------- ------------- 17.0/25.8 MB 582.3 kB/s eta 0:00:16\n",
            "   -------------------------- ------------- 17.0/25.8 MB 582.3 kB/s eta 0:00:16\n",
            "   -------------------------- ------------- 17.3/25.8 MB 582.9 kB/s eta 0:00:15\n",
            "   -------------------------- ------------- 17.3/25.8 MB 582.9 kB/s eta 0:00:15\n",
            "   --------------------------- ------------ 17.6/25.8 MB 584.0 kB/s eta 0:00:15\n",
            "   --------------------------- ------------ 17.6/25.8 MB 584.0 kB/s eta 0:00:15\n",
            "   --------------------------- ------------ 17.8/25.8 MB 585.3 kB/s eta 0:00:14\n",
            "   --------------------------- ------------ 17.8/25.8 MB 585.3 kB/s eta 0:00:14\n",
            "   --------------------------- ------------ 17.8/25.8 MB 585.3 kB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 18.1/25.8 MB 584.6 kB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 18.1/25.8 MB 584.6 kB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 18.4/25.8 MB 585.5 kB/s eta 0:00:13\n",
            "   ---------------------------- ----------- 18.6/25.8 MB 591.3 kB/s eta 0:00:13\n",
            "   ---------------------------- ----------- 18.6/25.8 MB 591.3 kB/s eta 0:00:13\n",
            "   ---------------------------- ----------- 18.6/25.8 MB 591.3 kB/s eta 0:00:13\n",
            "   ----------------------------- ---------- 18.9/25.8 MB 593.8 kB/s eta 0:00:12\n",
            "   ----------------------------- ---------- 18.9/25.8 MB 593.8 kB/s eta 0:00:12\n",
            "   ----------------------------- ---------- 19.1/25.8 MB 594.2 kB/s eta 0:00:12\n",
            "   ------------------------------ --------- 19.4/25.8 MB 597.9 kB/s eta 0:00:11\n",
            "   ------------------------------ --------- 19.4/25.8 MB 597.9 kB/s eta 0:00:11\n",
            "   ------------------------------ --------- 19.4/25.8 MB 597.9 kB/s eta 0:00:11\n",
            "   ------------------------------ --------- 19.4/25.8 MB 597.9 kB/s eta 0:00:11\n",
            "   ------------------------------ --------- 19.7/25.8 MB 596.3 kB/s eta 0:00:11\n",
            "   ------------------------------ --------- 19.9/25.8 MB 600.1 kB/s eta 0:00:10\n",
            "   ------------------------------ --------- 19.9/25.8 MB 600.1 kB/s eta 0:00:10\n",
            "   ------------------------------- -------- 20.2/25.8 MB 603.0 kB/s eta 0:00:10\n",
            "   ------------------------------- -------- 20.2/25.8 MB 603.0 kB/s eta 0:00:10\n",
            "   ------------------------------- -------- 20.4/25.8 MB 604.5 kB/s eta 0:00:09\n",
            "   ------------------------------- -------- 20.4/25.8 MB 604.5 kB/s eta 0:00:09\n",
            "   -------------------------------- ------- 20.7/25.8 MB 607.7 kB/s eta 0:00:09\n",
            "   -------------------------------- ------- 21.0/25.8 MB 612.8 kB/s eta 0:00:08\n",
            "   -------------------------------- ------- 21.0/25.8 MB 612.8 kB/s eta 0:00:08\n",
            "   -------------------------------- ------- 21.2/25.8 MB 614.5 kB/s eta 0:00:08\n",
            "   -------------------------------- ------- 21.2/25.8 MB 614.5 kB/s eta 0:00:08\n",
            "   --------------------------------- ------ 21.5/25.8 MB 616.5 kB/s eta 0:00:07\n",
            "   --------------------------------- ------ 21.5/25.8 MB 616.5 kB/s eta 0:00:07\n",
            "   --------------------------------- ------ 21.8/25.8 MB 617.5 kB/s eta 0:00:07\n",
            "   --------------------------------- ------ 21.8/25.8 MB 617.5 kB/s eta 0:00:07\n",
            "   ---------------------------------- ----- 22.0/25.8 MB 626.0 kB/s eta 0:00:07\n",
            "   ---------------------------------- ----- 22.0/25.8 MB 626.0 kB/s eta 0:00:07\n",
            "   ---------------------------------- ----- 22.3/25.8 MB 624.0 kB/s eta 0:00:06\n",
            "   ---------------------------------- ----- 22.3/25.8 MB 624.0 kB/s eta 0:00:06\n",
            "   ---------------------------------- ----- 22.3/25.8 MB 624.0 kB/s eta 0:00:06\n",
            "   ---------------------------------- ----- 22.5/25.8 MB 626.3 kB/s eta 0:00:06\n",
            "   ----------------------------------- ---- 22.8/25.8 MB 627.9 kB/s eta 0:00:05\n",
            "   ----------------------------------- ---- 22.8/25.8 MB 627.9 kB/s eta 0:00:05\n",
            "   ----------------------------------- ---- 23.1/25.8 MB 629.1 kB/s eta 0:00:05\n",
            "   ----------------------------------- ---- 23.1/25.8 MB 629.1 kB/s eta 0:00:05\n",
            "   ------------------------------------ --- 23.3/25.8 MB 630.8 kB/s eta 0:00:04\n",
            "   ------------------------------------ --- 23.3/25.8 MB 630.8 kB/s eta 0:00:04\n",
            "   ------------------------------------ --- 23.6/25.8 MB 634.1 kB/s eta 0:00:04\n",
            "   ------------------------------------ --- 23.6/25.8 MB 634.1 kB/s eta 0:00:04\n",
            "   ------------------------------------- -- 23.9/25.8 MB 636.1 kB/s eta 0:00:04\n",
            "   ------------------------------------- -- 23.9/25.8 MB 636.1 kB/s eta 0:00:04\n",
            "   ------------------------------------- -- 24.1/25.8 MB 641.5 kB/s eta 0:00:03\n",
            "   ------------------------------------- -- 24.1/25.8 MB 641.5 kB/s eta 0:00:03\n",
            "   ------------------------------------- -- 24.4/25.8 MB 641.6 kB/s eta 0:00:03\n",
            "   ------------------------------------- -- 24.4/25.8 MB 641.6 kB/s eta 0:00:03\n",
            "   -------------------------------------- - 24.6/25.8 MB 643.6 kB/s eta 0:00:02\n",
            "   -------------------------------------- - 24.6/25.8 MB 643.6 kB/s eta 0:00:02\n",
            "   -------------------------------------- - 24.9/25.8 MB 643.2 kB/s eta 0:00:02\n",
            "   -------------------------------------- - 24.9/25.8 MB 643.2 kB/s eta 0:00:02\n",
            "   -------------------------------------- - 24.9/25.8 MB 643.2 kB/s eta 0:00:02\n",
            "   ---------------------------------------  25.2/25.8 MB 642.9 kB/s eta 0:00:01\n",
            "   ---------------------------------------  25.2/25.8 MB 642.9 kB/s eta 0:00:01\n",
            "   ---------------------------------------  25.4/25.8 MB 644.6 kB/s eta 0:00:01\n",
            "   ---------------------------------------  25.7/25.8 MB 646.6 kB/s eta 0:00:01\n",
            "   ---------------------------------------  25.7/25.8 MB 646.6 kB/s eta 0:00:01\n",
            "   ---------------------------------------- 25.8/25.8 MB 645.6 kB/s eta 0:00:00\n",
            "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
            "Downloading aiohttp-3.12.12-cp311-cp311-win_amd64.whl (451 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
            "Downloading multidict-6.4.4-cp311-cp311-win_amd64.whl (38 kB)\n",
            "Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
            "Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
            "Installing collected packages: xxhash, pyyaml, pyarrow, propcache, multidict, fsspec, frozenlist, dill, colorama, attrs, aiohappyeyeballs, yarl, tqdm, multiprocess, aiosignal, huggingface-hub, aiohttp, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.12 aiosignal-1.3.2 attrs-25.3.0 colorama-0.4.6 datasets-3.6.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 huggingface-hub-0.32.6 multidict-6.4.4 multiprocess-0.70.16 propcache-0.3.2 pyarrow-20.0.0 pyyaml-6.0.2 tqdm-4.67.1 xxhash-3.5.0 yarl-1.20.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f01fa28-689d-4328-a6c2-cb9f0c79532d",
      "metadata": {
        "id": "1f01fa28-689d-4328-a6c2-cb9f0c79532d",
        "outputId": "aec12130-f4df-4b72-f963-d5022d4fde34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: absl-py in c:\\users\\john\\miniconda312\\lib\\site-packages (from rouge_score) (2.2.2)\n",
            "Requirement already satisfied: nltk in c:\\users\\john\\miniconda312\\lib\\site-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\john\\miniconda312\\lib\\site-packages (from rouge_score) (2.1.3)\n",
            "Requirement already satisfied: six>=1.14.0 in c:\\users\\john\\miniconda312\\lib\\site-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in c:\\users\\john\\miniconda312\\lib\\site-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in c:\\users\\john\\miniconda312\\lib\\site-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\john\\miniconda312\\lib\\site-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\john\\miniconda312\\lib\\site-packages (from nltk->rouge_score) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\john\\miniconda312\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py): started\n",
            "  Building wheel for rouge_score (setup.py): finished with status 'done'\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=25025 sha256=d06a4754eb6f8bc1abb7d81a4483b1227e1e79353432eddb40a2088d56b78ae9\n",
            "  Stored in directory: c:\\users\\john\\appdata\\local\\pip\\cache\\wheels\\85\\9d\\af\\01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55802039-6742-4c95-8539-22610c09f480",
      "metadata": {
        "id": "55802039-6742-4c95-8539-22610c09f480",
        "outputId": "3f774b3d-a1ad-4c6e-a240-ef728d4a0c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting click (from nltk)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: joblib in c:\\users\\john\\miniconda312\\lib\\site-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\john\\miniconda312\\lib\\site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\john\\miniconda312\\lib\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\john\\miniconda312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
            "   ------------- -------------------------- 0.5/1.5 MB 493.7 kB/s eta 0:00:02\n",
            "   -------------------- ------------------- 0.8/1.5 MB 610.3 kB/s eta 0:00:02\n",
            "   -------------------- ------------------- 0.8/1.5 MB 610.3 kB/s eta 0:00:02\n",
            "   --------------------------- ------------ 1.0/1.5 MB 613.9 kB/s eta 0:00:01\n",
            "   --------------------------- ------------ 1.0/1.5 MB 613.9 kB/s eta 0:00:01\n",
            "   --------------------------- ------------ 1.0/1.5 MB 613.9 kB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 1.3/1.5 MB 578.7 kB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.5/1.5 MB 598.3 kB/s eta 0:00:00\n",
            "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "Installing collected packages: click, nltk\n",
            "Successfully installed click-8.2.1 nltk-3.9.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efeb9711-f3c9-4a04-8015-bdfe96cab9f4",
      "metadata": {
        "id": "efeb9711-f3c9-4a04-8015-bdfe96cab9f4",
        "outputId": "64766c02-f1fa-409e-ba49-0620cd232b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\john\\miniconda312\\lib\\site-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\john\\miniconda312\\lib\\site-packages (from evaluate) (2.1.3)\n",
            "Requirement already satisfied: dill in c:\\users\\john\\miniconda312\\lib\\site-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\john\\miniconda312\\lib\\site-packages (from evaluate) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\john\\miniconda312\\lib\\site-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\john\\miniconda312\\lib\\site-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\john\\miniconda312\\lib\\site-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\john\\miniconda312\\lib\\site-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\john\\miniconda312\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\john\\miniconda312\\lib\\site-packages (from evaluate) (0.30.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\john\\miniconda312\\lib\\site-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\john\\miniconda312\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\john\\miniconda312\\lib\\site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\john\\miniconda312\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\john\\miniconda312\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\john\\miniconda312\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\john\\miniconda312\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\john\\miniconda312\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\john\\miniconda312\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\john\\miniconda312\\lib\\site-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: colorama in c:\\users\\john\\miniconda312\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\john\\miniconda312\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\john\\miniconda312\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\john\\miniconda312\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\john\\miniconda312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\john\\miniconda312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\john\\miniconda312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\john\\miniconda312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\john\\miniconda312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\john\\miniconda312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\john\\miniconda312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\john\\miniconda312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f19ce230",
      "metadata": {
        "id": "f19ce230",
        "outputId": "f6e9a79c-d457-4639-c6b5-63c7bb2fd1b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\John\\miniconda312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, TFAutoModelForSeq2SeqLM, create_optimizer, AdamWeightDecay, pipeline\n",
        "from datasets import load_dataset\n",
        "import tensorflow as tf\n",
        "from datasets import Dataset\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e7c7bb6",
      "metadata": {
        "id": "4e7c7bb6",
        "outputId": "f8699ad5-9e6f-450c-ce80-d918153d2f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79206908",
      "metadata": {
        "id": "79206908",
        "outputId": "6427c2ba-400d-46d7-bc04-d5ec68389a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\John\\Downloads\\Universidad\\\\AI Generativa Course\\Exercises\\Exercise2\\eng_small.csv\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['engl', 'spa'],\n",
            "        num_rows: 14074\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['engl', 'spa'],\n",
            "        num_rows: 6033\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "folder_path = r\"C:\\Users\\John\\Downloads\\Universidad\\\\AI Generativa Course\\Exercises\\Exercise2\"\n",
        "dataset_name = \"eng_small.csv\"\n",
        "path = os.path.join(folder_path, dataset_name)\n",
        "print(path)\n",
        "data = Dataset.from_csv(path, encoding='utf-8')\n",
        "data = data.train_test_split(test_size=0.1)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c22f593b-909d-48f5-8c13-890fe063162f",
      "metadata": {
        "id": "c22f593b-909d-48f5-8c13-890fe063162f",
        "outputId": "5ab2c53b-1c12-4ebb-f84b-d761b9972caa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\John\\miniconda312\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")  #google/flan-t5-small\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"t5-small\") #google/flan-t5-small\n",
        "#model = export_and_get_onnx_model('t5-small')\n",
        "\n",
        "prefix = \"translate: \"\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"engl\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "    labels = tokenizer(text_target=examples[\"spa\"], max_length=128, truncation=True) #max length was 128\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b302007e",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "90b33df218dc410287c8802bd267bb5c",
            "8f271bbbd8c5455cbc31c904fdafa662"
          ]
        },
        "id": "b302007e",
        "outputId": "2b45aeb6-c8c6-47df-b44e-aa6c4201a601"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90b33df218dc410287c8802bd267bb5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/14074 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f271bbbd8c5455cbc31c904fdafa662",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6033 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_data = data.map(preprocess_function, batched=True, remove_columns=[\"engl\", \"spa\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3cd75ab",
      "metadata": {
        "id": "f3cd75ab"
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    return {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors=\"tf\")\n",
        "optimizer = AdamWeightDecay(learning_rate=2e-4, weight_decay_rate=0.01) #2e-5 was before wd was 1e-2, Typically, 1e-4 and 3e-4 work well for most problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "076839d6",
      "metadata": {
        "id": "076839d6"
      },
      "outputs": [],
      "source": [
        "tf_train_set = model.prepare_tf_dataset(\n",
        "    tokenized_data[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "tf_test_set = model.prepare_tf_dataset(\n",
        "    tokenized_data[\"test\"],\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "541fe8a7",
      "metadata": {
        "id": "541fe8a7"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7674ab7-48bc-43b3-9dc4-b0d70ebd6fb6",
      "metadata": {
        "id": "b7674ab7-48bc-43b3-9dc4-b0d70ebd6fb6",
        "outputId": "a365c25e-bfc9-436e-992f-5026736fb417"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:From C:\\Users\\John\\miniconda312\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "879/879 [==============================] - 770s 845ms/step - loss: 2.2588 - val_loss: 1.5672\n",
            "Epoch 2/5\n",
            "879/879 [==============================] - 721s 820ms/step - loss: 1.6173 - val_loss: 1.2618\n",
            "Epoch 3/5\n",
            "879/879 [==============================] - 700s 796ms/step - loss: 1.3303 - val_loss: 1.1035\n",
            "Epoch 4/5\n",
            "879/879 [==============================] - 711s 809ms/step - loss: 1.1491 - val_loss: 1.0097\n",
            "Epoch 5/5\n",
            "879/879 [==============================] - 797s 906ms/step - loss: 1.0180 - val_loss: 0.9469\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x20739814fe0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=epochs, callbacks=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8fa8e30",
      "metadata": {
        "id": "e8fa8e30"
      },
      "outputs": [],
      "source": [
        "# Guarda el modelo entrenado\n",
        "folder_path = 'model'\n",
        "model_name = \"NMT-epocs-\" + str(epochs)\n",
        "path = os.path.join(folder_path, model_name + \".h5\")\n",
        "model.save_pretrained(path)\n",
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f69e21f",
      "metadata": {
        "id": "6f69e21f",
        "outputId": "9c72bb61-b781-43ec-e25a-1e8b4ac0ba8a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at model\\NMT-epocs-5.h5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
            "C:\\Users\\John\\miniconda312\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1156: UserWarning: \"translation\" task was used, instead of \"translation_XX_to_YY\", defaulting to \"translation_en_to_de\"\n",
            "  warnings.warn(\n",
            "Device set to use 0\n"
          ]
        }
      ],
      "source": [
        "#Para inferir desde aqu.\n",
        "model_name = \"NMT-epocs-\" + str(epochs)\n",
        "path = os.path.join(folder_path, model_name + \".h5\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(path, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "summarizer = pipeline(\"translation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    framework=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7c3925f",
      "metadata": {
        "id": "d7c3925f",
        "outputId": "26bef9bb-a976-4c2a-ad9a-6a7e7b228b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'translation_text': 'Es buen momento de ir a la boca.'}]\n",
            "time: 3.91 seconds\n"
          ]
        }
      ],
      "source": [
        "import timeit\n",
        "start_time = timeit.default_timer()\n",
        "\n",
        "text = \"translate: it's summer it is nice to go to the beach\"\n",
        "print(summarizer(text, min_length=4, max_length=100))\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(f\"time: {round(elapsed,2)} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef20d606-c6a8-403c-a028-fe622b431589",
      "metadata": {
        "id": "ef20d606-c6a8-403c-a028-fe622b431589"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "- This time use the larger dataset (eng.csv), use the same sentence and see the results.\n",
        "- Modify the code to graph and report the Rouge metric (*)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4431bc7-718c-485a-947e-aa54281b614f",
      "metadata": {
        "id": "e4431bc7-718c-485a-947e-aa54281b614f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5244d87-da20-4ff6-98db-b00cd2b665ac",
      "metadata": {
        "id": "d5244d87-da20-4ff6-98db-b00cd2b665ac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c34e795d-21d0-42c2-8799-5ccaec0e4413",
      "metadata": {
        "id": "c34e795d-21d0-42c2-8799-5ccaec0e4413"
      },
      "source": [
        "If you want to try other tokenizers, see next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f6c3bcf-10bc-4d3b-8c10-876d4754aaba",
      "metadata": {
        "id": "0f6c3bcf-10bc-4d3b-8c10-876d4754aaba"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "prefix = \"summarize: \"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"engl\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "    labels = tokenizer(text_target=examples[\"spa\"], max_length=128, truncation=True) #max length was 128\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d7a3d57-1e6d-4c42-8330-87e4c724853e",
      "metadata": {
        "id": "2d7a3d57-1e6d-4c42-8330-87e4c724853e"
      },
      "outputs": [],
      "source": [
        "from transformers import AlbertTokenizer, AlbertModel\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
        "model = AlbertModel.from_pretrained(\"albert-base-v2\")\n",
        "\n",
        "prefix = \"summarize: \"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"engl\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "    labels = tokenizer(text_target=examples[\"spa\"], max_length=128, truncation=True) #max length was 128\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6588008-4c89-4693-8b88-1b63663c34cd",
      "metadata": {
        "id": "b6588008-4c89-4693-8b88-1b63663c34cd"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "prefix = \"summarize: \"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"engl\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "    labels = tokenizer(text_target=examples[\"spa\"], max_length=128, truncation=True) #max length was 128\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bfc1cd5-41cd-44d2-b8b6-556475ad9eb7",
      "metadata": {
        "id": "5bfc1cd5-41cd-44d2-b8b6-556475ad9eb7"
      },
      "outputs": [],
      "source": [
        "from transformers import ElectraTokenizer, ElectraModel\n",
        "\n",
        "tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
        "mymodel = ElectraModel.from_pretrained(\"google/electra-small-discriminator\")\n",
        "\n",
        "prefix = \"summarize: \"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"engl\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "    labels = tokenizer(text_target=examples[\"spa\"], max_length=128, truncation=True) #max length was 128\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c33d6e30-4422-4fa4-8f68-0ec1aa54001c",
      "metadata": {
        "id": "c33d6e30-4422-4fa4-8f68-0ec1aa54001c"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "- Change summarize by translate\n",
        "- Graph the Rouge metric\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "11cfaa01c2d489d556e66fcaf9e384c983411f23416837fdb98f5bb9e5af2b30"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
