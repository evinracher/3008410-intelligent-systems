{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evinracher/3008410-intelligent-systems/blob/main/week1/exercise1/Generative_vs_Discriminative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0655c5a-3fcb-42fc-aa58-8d271949ab8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0655c5a-3fcb-42fc-aa58-8d271949ab8e",
        "outputId": "90ce6f06-1c32-4ea4-e755-f008787fa45b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89ee06f4-d158-4065-8afd-434af01712ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89ee06f4-d158-4065-8afd-434af01712ca",
        "outputId": "1b2cd55e-6f5f-4fde-ee0b-0eb688e63b52",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "pip install seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82c065fc-41d5-485d-926c-83904282b0b4",
      "metadata": {
        "id": "82c065fc-41d5-485d-926c-83904282b0b4"
      },
      "source": [
        "# Discriminative vs Generative"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4183c1c-3c40-486e-a5dc-8ef8f32dc4a5",
      "metadata": {
        "id": "e4183c1c-3c40-486e-a5dc-8ef8f32dc4a5"
      },
      "source": [
        "Consideraciones\n",
        "\n",
        "- Modelos Generativos pueden manejar datos faltantes de forma más natural.\n",
        "  \n",
        "- Modelos Discriminativos suelen tener mejor rendimiento para clasificar no para entender. El modelo no se preocupa por cómo es un email de spam en sí mismo, solo por qué palabras lo diferencian de uno que no es spam.\n",
        "\n",
        "- Los modelos generativos pueden ser más fáciles de interpretar en términos de cómo se generan los datos de cada clase. Naive Bayes podría (en teoría) generar un nuevo email de \"spam\" muestreando palabras según P(palabra | spam). La Regresión Logística no podría, solo dice, dada una combinación de palabras, si es más probable que sea spam o no.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b20b4b5-b552-430d-b7df-4028f5412a72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b20b4b5-b552-430d-b7df-4028f5412a72",
        "outputId": "bb0c2683-3650-451a-f6e3-3c1f1b21d8ff"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.feature_extraction.text import CountVectorizer # Sigue sin ser necesario aquí\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # Para visualizar la matriz de confusión\n",
        "import seaborn as sns      # Para visualizar la matriz de confusión\n",
        "\n",
        "nombre_archivo_datos = 'data_1000.csv' # --- Cargar los Datos ---\n",
        "try:\n",
        "    data = pd.read_csv(nombre_archivo_datos)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Asegúrate de que el archivo '{nombre_archivo_datos}' esté en el mismo directorio que el script.\")\n",
        "    exit()\n",
        "\n",
        "print(\"--- Datos Cargados ---\")\n",
        "print(f\"Total de ejemplos: {len(data)}\")\n",
        "print(data.head())\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- Preparación de los Datos ---\n",
        "# Las características (X) son las columnas de palabras\n",
        "# Obtenemos la lista de features dinámicamente del CSV (excluyendo 'email_id' y 'etiqueta')\n",
        "features = [col for col in data.columns if col not in ['email_id', 'etiqueta']]\n",
        "\n",
        "X = data[features]\n",
        "y = data['etiqueta']\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape[0]}\")\n",
        "print(f\"Tamaño del conjunto de prueba: {X_test.shape[0]}\")\n",
        "print(f\"Distribución de clases en y_train:\\n{y_train.value_counts(normalize=True)}\")\n",
        "print(f\"Distribución de clases en y_test:\\n{y_test.value_counts(normalize=True)}\")\n",
        "print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c89b053-48d1-4e79-8b03-3f3cd82cfae3",
      "metadata": {
        "id": "7c89b053-48d1-4e79-8b03-3f3cd82cfae3"
      },
      "source": [
        "\n",
        "1. Regresión Logística (Discriminativo):\n",
        "   - Modela directamente P(clase | email) usando la función logística: 1 / (1 + exp(-z)), donde z = w*x + b.\n",
        "   - Aprende los pesos 'w' (coeficientes) que mejor separan las clases.\n",
        "   - No intenta modelar cómo se ven los emails de cada clase por separado, solo cómo distinguirlos.\n",
        "   - Generalmente robusto y a menudo funciona muy bien en la práctica, especialmente si el supuesto de independencia de Naive Bayes no se cumple.\n",
        "   - Suele tener mejor rendimiento predictivo si el objetivo es solo la clasificación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c95de42b-9b6b-4290-b481-e95e37b557ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "id": "c95de42b-9b6b-4290-b481-e95e37b557ec",
        "outputId": "424b7b25-d320-4408-cae6-afb324d2563a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Parte 1: Modelo Discriminativo (Regresión Logística) ---\n",
        "print(\"--- Modelo Discriminativo: Regresión Logística ---\")\n",
        "\n",
        "log_reg_model = LogisticRegression(solver='liblinear', random_state=1200, C=1.0) # C es el inverso de la regularización\n",
        "log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = log_reg_model.predict(X_test)\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "\n",
        "print(f\"Exactitud (Accuracy) de Regresión Logística en el conjunto de prueba: {accuracy_lr:.4f}\")\n",
        "print(\"Reporte de Clasificación de Regresión Logística:\")\n",
        "print(classification_report(y_test, y_pred_lr, zero_division=0))\n",
        "\n",
        "# Matriz de confusión para Regresión Logística\n",
        "cm_lr = confusion_matrix(y_test, y_pred_lr, labels=log_reg_model.classes_)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Greens', xticklabels=log_reg_model.classes_, yticklabels=log_reg_model.classes_)\n",
        "plt.title('Matriz de Confusión - Regresión Logística')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nCoeficientes (pesos) aprendidos por Regresión Logística (P(Y|X)):\")\n",
        "# log_reg_model.coef_ tiene forma (1, n_features) para clasificación binaria\n",
        "# log_reg_model.classes_ nos dice el orden, ej. ['no spam', 'spam']. Si 'spam' es la clase 1:\n",
        "clase_positiva_idx = np.where(log_reg_model.classes_ == 'spam')[0][0] # Asumiendo 'spam' es la clase de interés\n",
        "if clase_positiva_idx == 1: # Si 'spam' es la segunda clase, los coeficientes son para ella\n",
        "    coefs = log_reg_model.coef_[0]\n",
        "else: # Si 'spam' es la primera clase, tomamos el negativo de los coeficientes (ya que LR modela P(clase_1|X))\n",
        "    coefs = -log_reg_model.coef_[0]\n",
        "\n",
        "intercept = log_reg_model.intercept_[0]\n",
        "if clase_positiva_idx == 0 : intercept = -intercept # Ajustar intercepto si 'spam' no es la clase '1'\n",
        "\n",
        "print(f\"(Coeficientes mostrados para la clase 'spam' como positiva)\")\n",
        "for feature_name, coef in zip(features, coefs):\n",
        "    print(f\"Coeficiente para {feature_name}: {coef:.4f}\")\n",
        "# print(f\"Intercepto (para clase 'spam'): {intercept:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\nInterpretación de los coeficientes:\")\n",
        "print(\"Un coeficiente positivo grande para una palabra significa que la presencia de esa palabra incrementa la probabilidad (log-odds) de que el email sea 'spam'.\")\n",
        "print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc894227-023d-41c5-933f-d03c5d922b41",
      "metadata": {
        "id": "dc894227-023d-41c5-933f-d03c5d922b41"
      },
      "source": [
        "\n",
        "2. Naive Bayes (Generativo):\n",
        "   - Modela P(palabra | clase) y P(clase).\n",
        "   - Usa el Teorema de Bayes para calcular P(clase | email) = P(email | clase) * P(clase) / P(email).\n",
        "   - P(email | clase) se asume como el producto de P(palabra_i | clase) (supuesto de independencia 'naive').\n",
        "   - Podríamos (conceptualmente) 'generar' emails de cada clase.\n",
        "   - Puede ser bueno con pocos datos, sensible a características irrelevantes si no hay buen suavizado.\n",
        "   - Al modelar P(X|Y), puede ser útil si se quieren generar nuevos datos o entender la distribución de cada clase.\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5433f84c-5a86-45d1-b565-46fbe7e1b513",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "5433f84c-5a86-45d1-b565-46fbe7e1b513",
        "outputId": "053a66a6-85ee-4be7-9d25-8fe0abc971ee"
      },
      "outputs": [],
      "source": [
        "# --- Parte 2: Modelo Generativo (Naive Bayes Multinomial) ---\n",
        "print(\"--- Modelo Generativo: Naive Bayes Multinomial ---\")\n",
        "\n",
        "nb_model = MultinomialNB() # alpha=1.0 por defecto para suavizado Laplace\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "\n",
        "print(f\"Exactitud (Accuracy) de Naive Bayes en el conjunto de prueba: {accuracy_nb:.4f}\")\n",
        "print(\"Reporte de Clasificación de Naive Bayes:\")\n",
        "print(classification_report(y_test, y_pred_nb, zero_division=0))\n",
        "\n",
        "# Matriz de confusión para Naive Bayes\n",
        "cm_nb = confusion_matrix(y_test, y_pred_nb, labels=nb_model.classes_)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', xticklabels=nb_model.classes_, yticklabels=nb_model.classes_)\n",
        "plt.title('Matriz de Confusión - Naive Bayes')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nProbabilidades a priori de las clases (aprendidas por Naive Bayes P(Y)):\")\n",
        "class_priors_nb = np.exp(nb_model.class_log_prior_)\n",
        "for i, class_name in enumerate(nb_model.classes_):\n",
        "    print(f\"P({class_name}) = {class_priors_nb[i]:.4f}\")\n",
        "\n",
        "print(\"\\n(Log) Probabilidades condicionales P(X_i | Y) (para algunas palabras):\")\n",
        "# Mostramos para las primeras 3 características\n",
        "for k, feature_name in enumerate(features[:3]):\n",
        "    print(f\"--- {feature_name} ---\")\n",
        "    for i, class_name in enumerate(nb_model.classes_):\n",
        "        log_prob_feature_given_class = nb_model.feature_log_prob_[i, k]\n",
        "        # La probabilidad de que la característica sea 1 (o el valor que tenga) dada la clase.\n",
        "        # Es más complejo interpretar esto directamente como P(feature=1|clase) sin mirar la implementación interna\n",
        "        # de cómo MultinomialNB maneja las características. Pero sí representa la contribución de esa feature a esa clase.\n",
        "        print(f\"  Log P({feature_name} presente | {class_name}) ~= {log_prob_feature_given_class:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\nPara 'generar' un email de spam (conceptual):\")\n",
        "print(\"Muestrearías palabras basándote en las P(palabra presente | 'spam') aprendidas.\")\n",
        "print(\"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5901244c-0025-40b9-b5a0-d4808262a455",
      "metadata": {
        "id": "5901244c-0025-40b9-b5a0-d4808262a455"
      },
      "source": [
        "### Preguntas del ejercicio 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bffb6abf-1419-478b-9b0a-ff02a0458668",
      "metadata": {
        "id": "bffb6abf-1419-478b-9b0a-ff02a0458668"
      },
      "source": [
        "--- Comparación y Discusión ---\n",
        "\n",
        "Preguntas:\n",
        "\n",
        "- Que pasa si se cambia el random state y la particion del dataset continua siendo mejor el modelo discriminativo?\n",
        "\n",
        "- ¿Qué modelo da más 'insights' sobre las características de CADA clase individualmente?\n",
        "  (R: Naive Bayes, a través de P(palabra|clase) )\n",
        "  \n",
        "- ¿Qué modelo se enfoca más directamente en la tarea de SEPARACIÓN?\n",
        "  (R: Regresión Logística)\n",
        "  \n",
        "- Si tuvieras que generar un nuevo email que parezca 'spam', ¿qué modelo sería más útil y por qué?\n",
        "  (R: Naive Bayes, porque modela la distribución de las características dentro de cada clase P(X|Y))\n",
        "\n",
        "- ¿Qué modelo crees que podría ser más sensible si las palabras clave fueran altamente correlacionadas (ej. 'gratis' y 'premio' casi siempre aparecen juntas)?\n",
        "  (R: Naive Bayes, porque su supuesto de independencia se violaría fuertemente. Regresión Logística podría manejarlo mejor.)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
